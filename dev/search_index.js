var documenterSearchIndex = {"docs": [

{
    "location": "index.html#",
    "page": "Home",
    "title": "Home",
    "category": "page",
    "text": ""
},

{
    "location": "index.html#RegularizedLeastSquares.jl-1",
    "page": "Home",
    "title": "RegularizedLeastSquares.jl",
    "category": "section",
    "text": "Solvers for Linear Inverse Problems using Regularization Techniques"
},

{
    "location": "index.html#Introduction-1",
    "page": "Home",
    "title": "Introduction",
    "category": "section",
    "text": "RegularizedLeastSquares.jl is a Julia package for solving large scale linear systems using different types of algorithm. Ill-conditioned problems arise in many areas of practical interest. To solve these problems, one often resorts to regularization techniques and non-linear problem formulations. This packages provides implementations for a variety of solvers, which are used in fields such as MPI and MRI.The implemented methods range from the l_2-regularized CGNR method to more general optimizers such as the Alternating Direction of Multipliers Method (ADMM) or the Split-Bregman method.For convenience, implementations of popular regularizers, such as l_1-regularization and TV regularization, are provided. On the other hand, hand-crafted regularizers can be used quite easily. For this purpose, a Regularization object needs to be build. The latter mainly contains the regularization parameter and a function to calculate the proximal map of a given input.Depending on the problem, it becomes unfeasible to store the full system matrix at hand. For this purpose, RegularizedLeastSquares.jl allows for the use of matrix-free operators. Such operators can be realized using the interface provided by the package LinearOperators.jl. Other interfaces can be used as well, as long as the product *(A,x) and the adjoint adjoint(A) are provided."
},

{
    "location": "index.html#Installation-1",
    "page": "Home",
    "title": "Installation",
    "category": "section",
    "text": "Install RegularizedLeastSquares.jl within Julia usingPkg.clone(\"https://github.com/tknopp/RegularizedLeastSquares.jl.git\")"
},

{
    "location": "index.html#Usage-1",
    "page": "Home",
    "title": "Usage",
    "category": "section",
    "text": "See Getting Started for an introduction to using the package"
},

{
    "location": "gettingStarted.html#",
    "page": "Getting Started",
    "title": "Getting Started",
    "category": "page",
    "text": ""
},

{
    "location": "gettingStarted.html#Getting-Started-1",
    "page": "Getting Started",
    "title": "Getting Started",
    "category": "section",
    "text": "To get familiar with the different aspects of RegularizedLeastSquares.jl, we will go through a simple example from the field of Compressed Sensing.In Addtion to RegularizedLeastSquares.jl, we will need the packages Images.jl and Random.jl, as well as PyPlot for visualization.using RegularizedLeastSquares, Images, PyPlot, RandomTo get started, let us generate a simple phantomN = 256\nI = shepp_logan(N)In this example, we consider an operator which randomly samples half of the pixels in the image. Such an operator and the corresponding measurement can be generated by calling# sampling operator\nidx = sort( shuffle( collect(1:N^2) )[1:div(N^2,2)] )\nA = SamplingOp(idx,(N,N))\n\n# generate undersampled data\ny = A*vec(I)To recover the image, we solve the TV-regularized least squares problem \\begin{equation}   \\underset{\\mathbf{x}}{argmin} \\frac{1}{2}\\vert\\vert \\mathbf{A}\\mathbf{x}-\\mathbf{y} \\vert\\vert_2^2 + λTV(\\mathbf{x}) . \\end{equation}For this purpose we build a TV regularizer with regularization parameter λ=001reg = Regularization(\"TV\", 0.01; shape=(N,N))To solve the CS problem, the Alternating Direction Method of Multipliers can be used. Thus, we build the corresponding solversolver = createLinearSolver(\"admm\",A; reg=reg, ρ=0.1, iterations=20)and apply it to our measurementIreco = solve(solver,y)\nIreco = reshape(Ireco,N,N)The original phantom and the reconstructed image are shown below(Image: Phantom) (Image: Reconstruction)"
},

{
    "location": "operators.html#",
    "page": "Matrices & Operators",
    "title": "Matrices & Operators",
    "category": "page",
    "text": ""
},

{
    "location": "operators.html#Matrices-and-Operators-1",
    "page": "Matrices & Operators",
    "title": "Matrices & Operators",
    "category": "section",
    "text": ""
},

{
    "location": "operators.html#Linear-Operator-Interface-1",
    "page": "Matrices & Operators",
    "title": "Linear Operator Interface",
    "category": "section",
    "text": "For the use with this packages, operators are not restricted to be actual Matrices. This is due to the effect that for many operators it is impractical to store the full matrix. Examples for this are Fourier transforms or Wavelet transforms which frequently arise in areas such as Image Processing and MRI.In order to work with the implemented solvers, the following methods need to be implemented for an operator A:*(A,x)\nadjoint(A)Moreover, the sparsifying transformations also recquire the implementation of the function \\(A,x). For an easy way to generate matrix-free operators, have a look at packages such as LinearOperators.jl and LinearMaps.jl."
},

{
    "location": "operators.html#Implemented-Operators-1",
    "page": "Matrices & Operators",
    "title": "Implemented Operators",
    "category": "section",
    "text": "For convenience, some common operators are implemented in this package. These includeDCT-II and DCT-IV\nDST\nFFT\nWavelet transformTo build these operators, one can use the method linearOperator(op::AbstractString, shape) - e.g.  shape = (256,256)\n  op = linearOperator(\"FFT\", shape)Here shape is the size of the Array to be transformed. Valid operate names are \"FFT\", \"DCT-II\", \"DCT-IV\", \"DST\" and \"Wavelet\". Alternatively, one can directly call the constructors for the desired operator."
},

{
    "location": "regularization.html#",
    "page": "Regularization",
    "title": "Regularization",
    "category": "page",
    "text": ""
},

{
    "location": "regularization.html#Regularization-1",
    "page": "Regularization",
    "title": "Regularization",
    "category": "section",
    "text": ""
},

{
    "location": "regularization.html#Defining-a-Regularizer-1",
    "page": "Regularization",
    "title": "Defining a Regularizer",
    "category": "section",
    "text": "When formulating inverse problems, a Regularizer is formulated as an additional term in a cost function, which has to be minimized. Popular optimizers often deal with a regularizers g, by computing the proximal map \\begin{equation}   prox_g (\\mathbf{x}) = \\underset{\\mathbf{u}}{argmin} \\frac{1}{2}\\vert\\vert \\mathbf{u}-\\mathbf{x} \\vert {\\vert}^2 + g(\\mathbf{x}). \\end{equation}In order to implement those kinds of algorithms,RegularizedLeastSquares defines the following typemutable struct Regularization <: AbstractRegularization\n  prox!::Function\n  norm::Function\n  λ::Float64\n  params::Dict{Symbol,Any}  # @TODO in die funcs\nendHere prox!(x,λ) is an in-place function which computes the proximal map on the input-vector x. The function norm computes the value of the corresponding term in the inverse problem and λ denotes the regularization parameter. If the Regularizer depends on additional parameters, those can be stored in params.This design makes it possible to use the solvers in RegularizedLeastSquares.jl with custom regulizers without any overhead, besides implementing the proximal map."
},

{
    "location": "regularization.html#Implemented-Regularizers-1",
    "page": "Regularization",
    "title": "Implemented Regularizers",
    "category": "section",
    "text": "So far, the following common regularizers are implemented:l_1 (\"L1\")\nl_2 (\"L2\")\nl_21 (\"L21\")\nLocally Low Rank regularization (\"LLR\")\nNuclear Norm regularization (\"Nuclear\")\nPositivity constrained (\"Positive\")\nProjection onto a convex set (\"Proj\")To build any of the implemted regularizers, one can use the methods Regularization(name::String, λ::AbstractFloat; kargs...) with the corresponding name (in brackets in the list above). For example, an l_1-regularizer can be build withshape = (256,256) # size of the underlying Array\nλ = 1.e-3         # regularization parameter\nreg = Regularization(\"L1\", λ; shape=shape)"
},

{
    "location": "solvers.html#",
    "page": "Solvers",
    "title": "Solvers",
    "category": "page",
    "text": ""
},

{
    "location": "solvers.html#Solvers-1",
    "page": "Solvers",
    "title": "Solvers",
    "category": "section",
    "text": ""
},

{
    "location": "solvers.html#Implemented-Solvers-1",
    "page": "Solvers",
    "title": "Implemented Solvers",
    "category": "section",
    "text": "So far, RegularizedLeastSquares.jl provides implementations for the following solvers:Kaczrmarz algorithm (\"kaczmarz\")\nCGNR (\"cgnr\")\nDax algorithm (with Kaczmarz) for unconstrained problems (\"daxkaczmarz\")\nDax algorithm for constrained problems (\"daxconstrained\")\nSolver for the Fused Lasso problem (\"fusedlasso\")\nFast Iterative Shrinkage Thresholding Algorithm (\"fista\")\nAlternating Direction of Multipliers Method (\"admm\")\nSplit Bregman method for constrained inverse Problems (\"splitBregman\")Here the strings given in brackets, denote the \"name\" of the respective solver in the repository."
},

{
    "location": "solvers.html#Creating-a-Solver-1",
    "page": "Solvers",
    "title": "Creating a Solver",
    "category": "section",
    "text": "To create a solver, one can invoke the method createLinearSolver as insolver = createLinearSolver(\"admm\",A; reg=reg, ρ=0.1, iterations=20)Here A denotes the system matrix and reg is either a Regularization or aVector{Regularization}. All further solver parameters can be passed as keyword arguments. To make things more compact, it can be usefull to collect all parameters in a Dict{Symnbol,Any}. In this way, the code snippet above can be written asparams=Dict{Symbol,Any}()\nparams[:reg] = reg\nparams[:ρ] = 0.1\nparams[:iterations] = 20\n\nsolver = createLinearSolver(\"admm\",A; params...)This notation can be convenient when a large number of parameters are set manually."
},

{
    "location": "API.html#",
    "page": "API",
    "title": "API",
    "category": "page",
    "text": ""
},

{
    "location": "API.html#API-1",
    "page": "API",
    "title": "API",
    "category": "section",
    "text": ""
},

{
    "location": "API.html#RegularizedLeastSquares.linearSolverList",
    "page": "API",
    "title": "RegularizedLeastSquares.linearSolverList",
    "category": "function",
    "text": "Return a list of all available linear solvers\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.createLinearSolver",
    "page": "API",
    "title": "RegularizedLeastSquares.createLinearSolver",
    "category": "function",
    "text": "createLinearSolver(solver::AbstractString, A; log::Bool=false, kargs...)\n\nThis method creates a solver. The supported solvers are methods typically used in MPI/MRI. All solvers return an approximate solution to STx = u. Function returns choosen solver.\n\nsolvers:\n\n\"kaczmarz\"        - kaczmarz method (the default)\n\"cgnr             - CGNR\n\"direct\"          - A direct solver using the backslash operator\n\"daxkaczmarz\"     - Dax algorithm (with Kaczmarz) for unconstrained problems\n\"daxconstrained\"  - Dax algorithm for constrained problems\n\"pseudoinverse\"   - approximates a solution using the More-Penrose pseudo inverse\n\"fusedlasso\"      - solver for the Fused-Lasso problem\n\"fista\"           - Fast Iterative Shrinkage Thresholding Algorithm\n\"admm\"            - Alternating Direcion of Multipliers Method\n\"splitBregman\"    - Split Bregman method for constrained & regularized inverse problems\n\n\n\n\n\n"
},

{
    "location": "API.html#Solvers-1",
    "page": "API",
    "title": "Solvers",
    "category": "section",
    "text": "RegularizedLeastSquares.linearSolverList\nRegularizedLeastSquares.createLinearSolver"
},

{
    "location": "API.html#RegularizedLeastSquares.Regularization",
    "page": "API",
    "title": "RegularizedLeastSquares.Regularization",
    "category": "type",
    "text": "Type describing Regularizers\n\nFields\n\nprox!::Function           - proximal map for the regularizer\nnorm::Function            - (semi-)norm for the regularizer\nλ::Float64                - regularization paramter\nparams::Dict{Symbol,Any}  - additional parameters\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.Regularization-Tuple{String,AbstractFloat}",
    "page": "API",
    "title": "RegularizedLeastSquares.Regularization",
    "category": "method",
    "text": "Regularization(name::String, λ::AbstractFloat; kargs...)\n\ncreate a Regularization object containing all the infos necessary to calculate a proximal map.\n\nvalid names\n\n\"L2\"\n\"L1\"\n\"L21\"\n\"TV\"\n\"LLR\"\n\"Nuclear\"\n\"Positive\"\n\"Proj\"\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.Regularization-Tuple{Array{String,1},Array{Float64,1}}",
    "page": "API",
    "title": "RegularizedLeastSquares.Regularization",
    "category": "method",
    "text": "Regularization(names::Vector{String}, λ::Vector{Float64}; kargs...)\n\ncreate a Regularization object containing all the infos necessary to calculate a proximal map. Valid names are the same as in Regularization(name::String, λ::AbstractFloat; kargs...).\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.RegularizationList",
    "page": "API",
    "title": "RegularizedLeastSquares.RegularizationList",
    "category": "function",
    "text": "RegularizationList()\n\nReturns a list of all available Regularizations\n\n\n\n\n\n"
},

{
    "location": "API.html#LinearAlgebra.normalize!",
    "page": "API",
    "title": "LinearAlgebra.normalize!",
    "category": "function",
    "text": "normalize!(reg::Regularization, data)\n\nscales the regularization parameter depending of the energy of the data (in-place).\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxL1!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxL1!",
    "category": "function",
    "text": "proxL1!(x::Array{T}, λ::Float64; sparseTrafo::Trafo=nothing, kargs...) where T\n\nperforms soft-thresholding - i.e. proximal map for the Lasso problem.\n\nArguments:\n\nx::Array{T}                 - Vector to apply proximal map to\nλ::Float64                  - regularization paramter\nsparseTrafo::Trafo=nothing  - sparsifying transform to apply\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxL2!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxL2!",
    "category": "function",
    "text": "proxL2!(x::Vector{T}, λ::Float64; kargs...) where T\n\nproximal map for Tikhonov regularization.\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxL21!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxL21!",
    "category": "function",
    "text": "proxL21!(x::Vector{T},λ::Float64; sparseTrafo::Trafo=nothing, slices::Int64=1, kargs...)\n\ngroup-soft-thresholding for l1/l2-regularization.\n\nArguments:\n\nx::Array{T}                 - Vector to apply proximal map to\nλ::Float64                  - regularization paramter\nsparseTrafo::Trafo=nothing  - sparsifying transform to apply\nslices::Int64=1             - number of elements per group\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxLLR!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxLLR!",
    "category": "function",
    "text": "proxLLR!(x::Vector{T}, λ::Float64=1e-6; kargs...) where T\n\nproximal map for LLR regularization using singular-value-thresholding\n\nArguments\n\nx::Vector{T}                - Vector to apply proximal map to\nλ::Float64                  - regularization parameter\nshape::Tuple{Int}=[]        - dimensions of the image\nblockSize::Tuple{Int}=[2;2] - size of patches to perform singluar value thresholding on\nrandshift::Bool=true        - randomly shifts the patches to ensure translation invariance\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxNuclear!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxNuclear!",
    "category": "function",
    "text": "proxNuclear!(x::Vector{T}, λ::Float64; svtShape::NTuple=[],kargs...)\n\napplies singular value soft-thresholding - i.e. the proximal map for the nuclear norm regularization.\n\nArguments:\n\nx::Array{T}          - Vector to apply proximal map to\nλ::Float64           - regularization paramter\nsvtShape::NTuple=[]  - size of the underlying matrix\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxPositive!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxPositive!",
    "category": "function",
    "text": "proxPositive!(x::Vector{T},λ::Float64=1.0;kargs...) where T\n\nenforce positivity and realness of solution `x`.\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxProj!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxProj!",
    "category": "function",
    "text": "proxProj!(x::Vector{T}, λ::Float64; projFunc=x->x, kargs...)\n\napplies the projection given by projFunc.\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.proxTV!",
    "page": "API",
    "title": "RegularizedLeastSquares.proxTV!",
    "category": "function",
    "text": "proxTV!(x::Vector{T}, λ::Float64; kargs...) where T\n\nproximal map for ansitropic TV regularization using the Fast Gradient Projection algorithm.\n\nArguments\n\nx::Array{T}             - Vector to apply proximal map to\nλ::Float64              - regularization paramter\nshape::NTuple=[]        - size of the underlying image\niterationsTV::Int64=20  - number of FGP iterations\nweights::Array=[]       - weights to apply to the image gradients\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normL1",
    "page": "API",
    "title": "RegularizedLeastSquares.normL1",
    "category": "function",
    "text": "normL1(x::Array{T}, λ::Float64; sparseTrafo::Trafo=nothing, kargs...) where T\n\nreturns the value of the L1-regularization term. Arguments are the same as in proxL1!\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normL2",
    "page": "API",
    "title": "RegularizedLeastSquares.normL2",
    "category": "function",
    "text": "normL2(x::Vector{T}, λ::Float64, kargs...)\n\nreturns the value of the L2-regularization term\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normL21",
    "page": "API",
    "title": "RegularizedLeastSquares.normL21",
    "category": "function",
    "text": "normL21(x::Vector{T}, λ::Float64; sparseTrafo::Trafo=nothing, slices::Int64=1, kargs...) where T\n\nreturn the value of the L21-regularization term. Arguments are the same as in proxL21!\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normLLR",
    "page": "API",
    "title": "RegularizedLeastSquares.normLLR",
    "category": "function",
    "text": "normLLR(x::Vector{T}, λ::Float64; kargs...) where T\n\nreturns the value of the LLR-regularization term. Arguments are the same is in proxLLR!\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normNuclear",
    "page": "API",
    "title": "RegularizedLeastSquares.normNuclear",
    "category": "function",
    "text": "normNuclear(x::Vector{T}, λ::Float64; svtShape::NTuple=[],kargs...) where T\n\nreturns the value of the nuclear norm regularization term. Arguments are the same as in proxNuclear!\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normPositive",
    "page": "API",
    "title": "RegularizedLeastSquares.normPositive",
    "category": "function",
    "text": "returns the value of the characteristic function of real, positive numbers.\nnormPositive(x) = (isreal(x)&&x>0) ? 0 : Inf\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normProj",
    "page": "API",
    "title": "RegularizedLeastSquares.normProj",
    "category": "function",
    "text": "normProj(x::Vector{T}, λ::Float64=0.0; projFunc=x->x, kargs...) where T\n\nevaluate indicator function of set to be projected onto.\n\n\n\n\n\n"
},

{
    "location": "API.html#RegularizedLeastSquares.normTV",
    "page": "API",
    "title": "RegularizedLeastSquares.normTV",
    "category": "function",
    "text": "normTV(x::Vector{T},λ::Float64;shape::NTuple=[],kargs...) where T\n\nreturns the value of the ansisotropic TV-regularization term. Arguments are the same as in proxTV!\n\n\n\n\n\n"
},

{
    "location": "API.html#Regularization-1",
    "page": "API",
    "title": "Regularization",
    "category": "section",
    "text": "RegularizedLeastSquares.Regularization\nRegularizedLeastSquares.Regularization(name::String, λ::AbstractFloat; kargs...)\nRegularizedLeastSquares.Regularization(names::Vector{String}, λ::Vector{Float64}; kargs...)\nRegularizedLeastSquares.RegularizationList\nRegularizedLeastSquares.normalize!\nRegularizedLeastSquares.proxL1!\nRegularizedLeastSquares.proxL2!\nRegularizedLeastSquares.proxL21!\nRegularizedLeastSquares.proxLLR!\nRegularizedLeastSquares.proxNuclear!\nRegularizedLeastSquares.proxPositive!\nRegularizedLeastSquares.proxProj!\nRegularizedLeastSquares.proxTV!\nRegularizedLeastSquares.normL1\nRegularizedLeastSquares.normL2\nRegularizedLeastSquares.normL21\nRegularizedLeastSquares.normLLR\nRegularizedLeastSquares.normNuclear\nRegularizedLeastSquares.normPositive\nRegularizedLeastSquares.normProj\nRegularizedLeastSquares.normTV"
},

{
    "location": "API.html#LinearOperators-1",
    "page": "API",
    "title": "LinearOperators",
    "category": "section",
    "text": "RegularizedLeastSquares.linearOperator(op::AbstractString, shape)\nRegularizedLeastSquares.linearOperatorList\nRegularizedLeastSquares.DCTOp\nRegularizedLeastSquares.DSTOp\nRegularizedLeastSquares.FFTOp\nRegularizedLeastSquares.SamplingOp\nRegularizedLeastSquares.WaveletOp\nRegularizedLeastSquares.WeightingOp"
},

]}
